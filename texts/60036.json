{"text_id":60036,"tokens":["Verification"," of"," properties"," expressed"," as","-","regular"," languages"," such"," as"," L","TL"," can","\n","benefit"," hugely"," from"," stutter","-","ins","ensitivity",","," using"," a"," diverse"," set"," of"," reduction","\n","strategies","."," However"," properties"," that"," are"," not"," stutter","-","insensitive",","," for"," instance","\n","due"," to"," the"," use"," of"," the"," ne","Xt"," operator"," of"," L","TL"," or"," to"," some"," form"," of"," counting"," in"," the","\n","logic",","," are"," not"," covered"," by"," these"," techniques"," in"," general","."," We"," propose"," in"," this"," paper","\n","to"," study"," a"," weaker"," property"," than"," stutter","-","ins","ensitivity","."," In"," a"," stutter"," insensitive","\n","language"," both"," adding"," and"," removing"," stutter"," to"," a"," word"," does"," not"," change"," its","\n","acceptance",","," any"," stuttering"," can"," be"," abstracted"," away",";"," by"," decom","posing"," this","\n","equi","valence"," relation"," into"," two"," implications"," we"," obtain"," weaker"," conditions","."," We","\n","define"," a"," shortening"," insensitive"," language"," where"," any"," word"," that"," st","utters"," less"," than","\n","a"," word"," in"," the"," language"," must"," also"," belong"," to"," the"," language","."," A"," lengthening","\n","insensitive"," language"," has"," the"," dual"," property","."," A"," semi","-","decision"," procedure"," is"," then","\n","introduced"," to"," reliably"," prove"," shortening"," insensitive"," properties"," or"," deny","\n","length","ening"," insensitive"," properties"," while"," working"," with"," a"," reduction"," of"," a"," system",".","\n","A"," reduction"," has"," the"," property"," that"," it"," can"," only"," shorten"," runs","."," Li","pton","'","s","\n","transaction"," reductions"," or"," Petri"," net"," agglomer","ations"," are"," examples"," of"," eligible","\n","structural"," reduction"," strategies","."," An"," implementation"," and"," experimental"," evidence"," is","\n","provided"," showing"," most"," non","random"," properties"," sensitive"," to"," stutter"," are"," actually","\n","short","ening"," or"," lengthening"," insensitive","."," Performance"," of"," experiments"," on"," a"," large","\n","(","random",")"," benchmark"," from"," the"," model","-","checking"," competition"," indicate"," that"," despite","\n","being"," a"," semi","-","decision"," procedure",","," the"," approach"," can"," still"," improve"," state"," of"," the","\n","art"," verification"," tools","."],"sub_source":"arxiv","model":"human","label":0}