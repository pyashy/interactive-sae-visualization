{"text_id":77703,"tokens":["The"," main"," contribution"," of"," this"," work"," is"," to"," provide"," an"," end","-","to","-","end"," deep"," learning"," framework"," for"," point"," cloud"," processing"," that"," can"," be"," used"," in"," many"," applications"," such"," as"," autonomous"," driving",".","\n","In"," particular",","," they"," propose"," a"," novel"," network"," architecture"," called"," Deep","Sets"," which"," combines"," set","-","processing"," operations"," (","union","/","intersection",")"," into"," standard"," convolutional"," layers",".","  ","The"," authors"," show"," how"," their"," approach"," out","performs"," state","-","of","-","the","-","art"," methods"," on"," several"," benchmark"," datasets"," including"," KIT","TI"," object"," detection"," dataset","."," ","\n","Strengths",":"," ","\n","1","."," They"," introduce"," new"," techniques"," combining"," sets"," and"," points"," clouds"," together"," using"," CNN","s",".","\n","2","."," Their"," method"," achieves"," better"," results"," than"," previous"," works"," based"," only"," on"," ","3","D"," data"," without"," any"," additional"," information"," like"," RGB"," images"," from"," cameras",".","\n","3","."," It"," also"," shows"," good"," performance"," when"," applied"," directly"," to"," raw"," Li","DAR"," scans"," instead"," of"," pre","processed"," ones"," Weak","nesses",":"],"sub_source":"peerread","model":"bloomz","label":1}