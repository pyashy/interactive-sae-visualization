{"text_id":229095,"tokens":["The"," process"," of"," collecting"," and"," annot","ating"," training"," data"," may"," introduce"," distribution"," artifacts"," which"," may"," limit"," the"," ability"," of"," models"," to"," learn"," correct"," generalization"," behavior","."," We"," identify"," failure"," modes"," of"," S","OTA"," methods"," on"," standard"," vision"," benchmarks"," for"," two"," datasets"," that"," we"," crowd","-","sourced"," by"," taking"," a"," random"," sampling"," strategy"," from"," our"," original"," dataset",","," using"," simple"," human"," annotations"," (","attention"," mask",")"," rather"," than"," automated"," object"," detectors"," or"," bounding"," boxes",".'"," author",":"],"sub_source":"sci_gen","model":"gpt_neox","label":1}