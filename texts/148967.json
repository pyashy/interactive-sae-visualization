{"text_id":148967,"tokens":["The"," authors"," propose"," an"," approach"," for"," learning"," from"," un","labeled"," data"," in"," low"," resource"," settings"," where"," labeled"," training"," examples"," are"," scarce",".","\n","They"," use"," cross"," lingual"," projections"," of"," word"," embeddings"," as"," features"," that"," can"," be"," learned"," with"," few"," labels"," (","fe","wer"," than"," ","1","0","0",")."," They"," show"," how"," this"," method"," performs"," on"," two"," tasks"," -"," part","-","of","-","speech"," tagging"," and"," named"," entity"," recognition","."," ","\n","This"," is"," a"," very"," interesting"," work"," which"," makes"," several"," contributions"," including"," proposing"," new"," methods"," for"," projecting"," embedding"," spaces"," across"," languages",".","  ","The"," results"," they"," report"," seem"," promising"," but"," I"," have"," some"," concerns"," about"," their"," experimental"," setup","."," ","\n\n","First"," off",","," it"," seems"," like"," there"," should"," not"," really"," be"," any"," difference"," between"," the"," performance"," reported"," here"," vs","."," if"," you"," were"," just"," doing"," supervised"," learning"," directly"," over"," English"," text"," since"," all"," your"," test"," sets"," contain"," only"," English"," sentences"," anyway","!"," ","\n","Second",","," while"," it","'","s"," true"," that"," many"," NLP"," applications"," require"," language","-","independent"," representations",","," most"," real","-","world"," scenarios"," will"," involve"," multiple"," languages"," so"," I","'","d"," expect"," these"," models"," would"," need"," to"," perform"," well"," at"," least"," on"," one"," other"," language"," besides"," English"," before"," being"," useful"," outside"," research"," labs",".","  ","\n\n","Third","ly",","," I","'","m"," curious"," why"," the"," authors"," chose"," to"," focus"," exclusively"," on"," Wikipedia"," articles","?"],"sub_source":"peerread","model":"bloomz","label":1}