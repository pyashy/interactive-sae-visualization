{"text_id":135404,"tokens":["The"," authors"," propose"," an"," actor","-","critic"," algorithm"," that"," uses"," experience"," replay"," to"," improve"," sample"," efficiency",".","\n","This"," is"," noteworthy"," because"," it"," has"," been"," shown"," in"," previous"," work"," (","M","nih"," et"," al",".,"," ","2","0","1","5",")"," that"," using"," experience"," replay"," can"," significantly"," reduce"," training"," time"," for"," deep"," reinforcement"," learning"," algorithms",".","  ","The"," proposed"," method"," also"," incorporates"," target"," network"," updates"," which"," are"," known"," to"," help"," stabilize"," RL"," agents"," during"," training","."," ","\n","However",","," there"," seems"," to"," be"," no"," discussion"," of"," how"," these"," techniques"," were"," combined"," into"," one"," model"," nor"," any"," explanation"," as"," to"," why"," they"," should"," produce"," better"," results"," than"," other"," methods"," such"," as"," D","QN",".","  ","\n","In"," addition",","," I"," would"," have"," liked"," more"," details"," on"," hyper","parameters"," used"," throughout"," this"," study",".","   ","Finally",",","  ","while"," the"," experiments"," show"," improved"," performance"," over"," baseline"," models"," trained"," without"," experience"," replay","  ","it","'","s"," unclear"," whether"," those"," improvements"," come"," at"," significant"," computational"," cost","."," ","\n\n","Overall",","," I","'","d"," give"," ","3"," stars"],"sub_source":"peerread","model":"bloomz","label":1}